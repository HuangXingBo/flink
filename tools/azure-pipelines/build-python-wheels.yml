# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

jobs:
  - job: compile_${{parameters.stage_name}}
    pool:
      vmImage: 'ubuntu-16.04'
    container: flink-build-container
    timeoutInMinutes: 240
    cancelTimeoutInMinutes: 1
    workspace:
      clean: all # this cleans the entire workspace directory before running a new job
      # It is necessary because the custom build machines are reused for tests.
      # See also https://docs.microsoft.com/en-us/azure/devops/pipelines/process/phases?view=azure-devops&tabs=yaml#workspace

    steps:
      # The cache task is persisting the .m2 directory between builds, so that
      # we do not have to re-download all dependencies from maven central for
      # each build. The hope is that downloading the cache is faster than
      # all dependencies individually.
      # In this configuration, we use a hash over all committed (not generated) .pom files
      # as a key for the build cache (CACHE_KEY). If we have a cache miss on the hash
      # (usually because a pom file has changed), we'll fall back to a key without
      # the pom files (CACHE_FALLBACK_KEY).
      # Offical documentation of the Cache task: https://docs.microsoft.com/en-us/azure/devops/pipelines/caching/?view=azure-devops
      #  - task: Cache@2
      - task: CacheBeta@1
        inputs:
          key: $(CACHE_KEY)
          restoreKeys: $(CACHE_FALLBACK_KEY)
          path: $(MAVEN_CACHE_FOLDER)
        continueOnError: true # continue the build even if the cache fails.
        displayName: Cache Maven local repo
      # Compile
      - script: STAGE=compile ${{parameters.environment}} ./tools/azure_controller.sh compile
        displayName: Build

      # upload artifacts for next stage
      - task: PublishPipelineArtifact@1
        inputs:
          path: $(CACHE_FLINK_DIR)
          artifact: FlinkCompileCacheDir

  - job: LinuxSDist
    dependsOn: compile_${{parameters.stage_name}}
    pool:
      vmImage: 'ubuntu-latest'
    variables:
      python.architecture: 'none'
    steps:
      # download artifacts
      - task: DownloadPipelineArtifact@2
        inputs:
          path: $(CACHE_FLINK_DIR)
          artifact: FlinkCompileCacheDir
      # recreate "build-target" symlink for python tests
      - script: |
          mkdir -p flink-dist/target/flink-$(VERSION)-bin
          ln -snf $(CACHE_FLINK_DIR)/flink-dist/target/flink-$(VERSION)-bin/flink-$(VERSION) `pwd`/flink-dist/target/flink-$(VERSION)-bin/flink-$(VERSION)
        displayName: Recreate 'build-target' symlink
      - task: UsePythonVersion@0
        inputs:
          versionSpec: '3.7'
      - script: |
          python -m pip install --upgrade pip setuptools
          python -m pip install wheel
          python -m pip install apache-beam==2.19.0
          python -m pip install cython==0.28.1
        displayName: Install sdist deps
      - script: |
          cd flink-python
          python setup.py sdist
          ls dist/
        displayName: Prepare sdist
      - task: PublishPipelineArtifact@0
        inputs:
          artifactName: 'sdist_package'
          targetPath: 'flink-python/dist'

  - job: BuildWheels
    dependsOn: compile_${{parameters.stage_name}}
    strategy:
      matrix:
        linux:
          vm-label: 'ubuntu-16.04'
        mac:
          vm-label: 'macOS-10.15'
    pool:
      vmImage: $(vm-label)
    steps:
      # download artifacts
      - task: DownloadPipelineArtifact@2
        inputs:
          path: $(CACHE_FLINK_DIR)
          artifact: FlinkCompileCacheDir
      # recreate "build-target" symlink for python tests
      - script: |
          mkdir -p flink-dist/target/flink-$(VERSION)-bin
          ln -snf $(CACHE_FLINK_DIR)/flink-dist/target/flink-$(VERSION)-bin/flink-$(VERSION) `pwd`/flink-dist/target/flink-$(VERSION)-bin/flink-$(VERSION)
        displayName: Recreate 'build-target' symlink
      - script: |
          cd flink-python
          bash dev/build-wheels.sh
        displayName: Build wheels
      - task: PublishPipelineArtifact@0
        inputs:
          artifactName: 'wheel_$(Agent.OS)_$(Agent.JobName)'
          targetPath: 'flink-python/dist'
